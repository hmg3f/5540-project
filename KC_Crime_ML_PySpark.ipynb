{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in ./venv/lib/python3.13/site-packages (0.19.5)\n",
      "Requirement already satisfied: branca>=0.6.0 in ./venv/lib/python3.13/site-packages (from folium) (0.8.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in ./venv/lib/python3.13/site-packages (from folium) (3.1.6)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from folium) (2.2.5)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in ./venv/lib/python3.13/site-packages (from folium) (2025.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2>=2.9->folium) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->folium) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->folium) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->folium) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->folium) (2025.4.26)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (2.2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: findspark in ./venv/lib/python3.13/site-packages (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.13/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pyarrow in ./venv/lib/python3.13/site-packages (20.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./venv/lib/python3.13/site-packages (from seaborn) (2.2.5)\n",
      "Requirement already satisfied: pandas>=1.2 in ./venv/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./venv/lib/python3.13/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.13/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./venv/lib/python3.13/site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install folium\n",
    "!pip install numpy\n",
    "!pip install findspark\n",
    "!pip install pandas\n",
    "!pip install pyarrow\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q http://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
    "!tar xf spark-3.5.1-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/default\"\n",
    "os.environ[\"SPARK_HOME\"] = \"spark-3.5.1-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0q-bXD2V41dt"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === SETUP ===\n",
    "# Define color map used across models\n",
    "crime_color_map = {\n",
    "    'Person': 'red',\n",
    "    'Property': 'blue',\n",
    "    'Society': 'orange',\n",
    "    'Unknown': 'gray'\n",
    "}\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZdxgaJJR496R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/28 00:29:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/28 00:29:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"KC_Crime_Prediction\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"hdfs://localhost:9010/data/final_crime_data_F.csv\", header=True, inferSchema=True)\n",
    "# df = spark.read.csv(\"data/final_crime_data_F.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# === CRIME TYPE LABELING ===\n",
    "df = df.withColumn(\"Crime_Type\", expr(\"\"\"\n",
    "    CASE\n",
    "        WHEN Person >= Property AND Person >= Society AND Person >= Unknown THEN 'Person'\n",
    "        WHEN Property >= Person AND Property >= Society AND Property >= Unknown THEN 'Property'\n",
    "        WHEN Society >= Person AND Society >= Property AND Society >= Unknown THEN 'Society'\n",
    "        ELSE 'Unknown'\n",
    "    END\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9ncZ1H65FxX",
    "outputId": "b8afa92a-d39b-4416-d828-817af11b4cde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest predictions saved to predicted_crimes_2024_rf.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === SPLIT DATA ===\n",
    "train_df = df.filter(col(\"Year\").isin([2022, 2023]))\n",
    "predict_df = df.filter(col(\"Year\") == 2024)\n",
    "\n",
    "# === RANDOM FOREST PIPELINE ===\n",
    "label_indexer = StringIndexer(inputCol=\"Crime_Type\", outputCol=\"Crime_Label\")\n",
    "feature_cols = [\"Lat\", \"Lon\", \"Month\", \"Hour\", \"Day_of_Week\", \"Bus_Stop_Distance\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"Crime_Label\", featuresCol=\"features\", numTrees=100)\n",
    "pipeline_rf = Pipeline(stages=[label_indexer, assembler, rf])\n",
    "model_rf = pipeline_rf.fit(train_df)\n",
    "predictions_rf = model_rf.transform(predict_df)\n",
    "\n",
    "# Convert predictions to labels\n",
    "rf_labels = model_rf.stages[0].labels\n",
    "label_udf = udf(lambda i: rf_labels[int(i)], StringType())\n",
    "predictions_rf = predictions_rf.withColumn(\"Predicted_Crime_Type\", label_udf(col(\"prediction\")))\n",
    "\n",
    "# === EXPORT RF PREDICTIONS ===\n",
    "predict_rf_pd = predictions_rf.select(\"Lat\", \"Lon\", \"Month\", \"Hour\", \"Day_of_Week\", \"Bus_Stop_Distance\", \"Zip Code\", \"Predicted_Crime_Type\").toPandas()\n",
    "predict_rf_pd.to_csv(\"predicted_crimes_2024_rf.csv\", index=False)\n",
    "print(\"Random Forest predictions saved to predicted_crimes_2024_rf.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oLAQKBU5LvJ",
    "outputId": "097ef681-392c-4a30-ac3f-9bf72dd4f317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped RF maps: RF_Crime_Prediction_Maps_2024.zip\n"
     ]
    }
   ],
   "source": [
    "# === RANDOM FOREST MAP ZIPPING ===\n",
    "rf_output_dir = \"updated_crime_prediction_maps\"\n",
    "os.makedirs(rf_output_dir, exist_ok=True)\n",
    "rf_map_files = []\n",
    "\n",
    "monthly_crime_counts_rf = predict_rf_pd.groupby([\"Month\", \"Predicted_Crime_Type\"]).size().unstack(fill_value=0)\n",
    "\n",
    "for month in sorted(predict_rf_pd[\"Month\"].unique()):\n",
    "    month_df = predict_rf_pd[predict_rf_pd[\"Month\"] == month]\n",
    "    crime_map = folium.Map(location=[month_df[\"Lat\"].mean(), month_df[\"Lon\"].mean()], zoom_start=11)\n",
    "\n",
    "    for _, row in month_df.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"Lat\"], row[\"Lon\"]],\n",
    "            tooltip=f\"Zip Code: {row['Zip Code']}\",\n",
    "            radius=3,\n",
    "            color=crime_color_map.get(row[\"Predicted_Crime_Type\"], 'gray'),\n",
    "            fill=True,\n",
    "            fill_opacity=0.6\n",
    "        ).add_to(crime_map)\n",
    "\n",
    "    crime_counts = monthly_crime_counts_rf.loc[month]\n",
    "    legend_items = ''.join([\n",
    "        f\"&nbsp;<i style='color:{crime_color_map.get(crime, 'gray')};'>●</i> {crime}: {count}<br>\"\n",
    "        for crime, count in crime_counts.items()\n",
    "    ])\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"position: fixed;\n",
    "    bottom: 50px; left: 50px; width: 180px; height: auto;\n",
    "    border:2px solid grey; z-index:9999; font-size:14px;\n",
    "    background-color:white; padding: 5px;\">\n",
    "    &nbsp;<b>RF Crime Prediction - {month}</b><br>\n",
    "    {legend_items}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    crime_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "    map_file = f\"{rf_output_dir}/RF_Crime_Map_Month_{month}.html\"\n",
    "    crime_map.save(map_file)\n",
    "    rf_map_files.append(map_file)\n",
    "\n",
    "with zipfile.ZipFile(\"RF_Crime_Prediction_Maps_2024.zip\", 'w') as zipf:\n",
    "    for file in rf_map_files:\n",
    "        zipf.write(file, arcname=os.path.basename(file))\n",
    "print(\"Zipped RF maps: RF_Crime_Prediction_Maps_2024.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AZHdwFEy5QFC"
   },
   "outputs": [],
   "source": [
    "# === ZIP-CODE HEATMAP RF ===\n",
    "zip_grouped = predict_rf_pd.groupby(\"Zip Code\")\n",
    "\n",
    "m = folium.Map(location=[predict_rf_pd['Lat'].mean(), predict_rf_pd['Lon'].mean()], zoom_start=11)\n",
    "for zip_code, group in zip_grouped:\n",
    "    heat_data = [[row['Lat'], row['Lon']] for _, row in group.iterrows()]\n",
    "    HeatMap(heat_data, radius=10, blur=15, max_zoom=1).add_to(m)\n",
    "\n",
    "    lat_center = group['Lat'].mean()\n",
    "    lon_center = group['Lon'].mean()\n",
    "    folium.map.Marker(\n",
    "        [lat_center, lon_center],\n",
    "        icon=folium.DivIcon(html=f\"\"\"<div style='font-size: 12px; color: white;'><b>{zip_code}</b></div>\"\"\"))\n",
    "\n",
    "crime_type_counts = predict_rf_pd['Predicted_Crime_Type'].value_counts().to_dict()\n",
    "legend_items = ''.join([\n",
    "    f\"&nbsp;<i style='color:{crime_color_map.get(crime, 'gray')};'>●</i> {crime}: {count}<br>\"\n",
    "    for crime, count in crime_type_counts.items()\n",
    "])\n",
    "legend_html = f\"\"\"\n",
    " <div style=\"position: fixed;\n",
    " bottom: 50px; left: 50px; width: 200px; height: auto;\n",
    " border:2px solid grey; z-index:9999; font-size:14px;\n",
    " background-color:white; padding: 10px;\">\n",
    " <b>2024 RF Predicted Crime Types</b><br>\n",
    " {legend_items}\n",
    " </div>\n",
    "\"\"\"\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "m.save(\"2024_RF_Crime_Heat_Map_by_Zip_Code.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tCzs-115RVv",
    "outputId": "f06c8310-a37d-47ce-bfed-a72486b2795c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/28 01:11:33 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "[Stage 181:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network predictions saved to predicted_crimes_2024_mlp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# === NEURAL NETWORK PIPELINE ===\n",
    "# Determine class count and input size for MLP\n",
    "class_count = len(rf_labels)\n",
    "input_size = len(feature_cols)\n",
    "layers = [6, 64, 124, 256, 512, 256, 124, 64, class_count]  # Deep MLP to match PyTorch-style architecture  # Match structure more closely to sklearn MLP used earlier  # Example MLP architecture\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(labelCol=\"Crime_Label\", featuresCol=\"features\", maxIter=100, layers=layers, blockSize=128, seed=42)\n",
    "pipeline_mlp = Pipeline(stages=[label_indexer, assembler, mlp])\n",
    "model_mlp = pipeline_mlp.fit(train_df)\n",
    "predictions_mlp = model_mlp.transform(predict_df)\n",
    "\n",
    "# Convert MLP predictions to labels\n",
    "mlp_labels = model_mlp.stages[0].labels\n",
    "label_udf_mlp = udf(lambda i: mlp_labels[int(i)], StringType())\n",
    "predictions_mlp = predictions_mlp.withColumn(\"Predicted_Crime_Type_MLP\", label_udf_mlp(col(\"prediction\")))\n",
    "\n",
    "# Export MLP predictions if needed\n",
    "predict_mlp_pd = predictions_mlp.select(\"Lat\", \"Lon\", \"Month\", \"Hour\", \"Day_of_Week\", \"Bus_Stop_Distance\", \"Zip Code\", \"Predicted_Crime_Type_MLP\").toPandas()\n",
    "predict_mlp_pd.to_csv(\"predicted_crimes_2024_mlp.csv\", index=False)\n",
    "print(\"Neural Network predictions saved to predicted_crimes_2024_mlp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6uK95wOP5Uvu"
   },
   "outputs": [],
   "source": [
    "# === KMEANS CLUSTERING ===\n",
    "kmeans_df = predictions_rf.select(\"Lat\", \"Lon\").dropna()\n",
    "kmeans_assembler = VectorAssembler(inputCols=[\"Lat\", \"Lon\"], outputCol=\"features\")\n",
    "kmeans_features = kmeans_assembler.transform(kmeans_df)\n",
    "\n",
    "kmeans = KMeans(k=16, seed=42, featuresCol=\"features\", predictionCol=\"Cluster\")\n",
    "kmeans_model = kmeans.fit(kmeans_features)\n",
    "kmeans_result = kmeans_model.transform(kmeans_features).select(\"Lat\", \"Lon\", \"Cluster\")\n",
    "kmeans_pd = kmeans_result.toPandas()\n",
    "\n",
    "sil_score = silhouette_score(kmeans_pd[[\"Lat\", \"Lon\"]], kmeans_pd[\"Cluster\"])\n",
    "\n",
    "cluster_colors = [\n",
    "    'red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray',\n",
    "    'olive', 'cyan', 'magenta', 'lime', 'yellow', 'navy', 'maroon', 'salmon']\n",
    "\n",
    "kmeans_map = folium.Map(location=[kmeans_pd['Lat'].mean(), kmeans_pd['Lon'].mean()], zoom_start=11)\n",
    "\n",
    "for _, row in kmeans_pd.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Lat'], row['Lon']],\n",
    "        radius=3,\n",
    "        color = cluster_colors[int(row['Cluster']) % len(cluster_colors)],\n",
    "        fill=True,\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(kmeans_map)\n",
    "\n",
    "legend_items = ''.join([\n",
    "    f\"&nbsp;<i style='color:{cluster_colors[i]};'>●</i> Cluster {i+1}<br>\"\n",
    "    for i in range(16)\n",
    "])\n",
    "legend_html = f\"\"\"\n",
    " <div style=\"position: fixed;\n",
    " bottom: 50px; left: 50px; width: 200px; height: auto;\n",
    " border:2px solid grey; z-index:9999; font-size:14px;\n",
    " background-color:white; padding: 10px;\">\n",
    " <b>K-Means Clusters (2024)</b><br>\n",
    " {legend_items}\n",
    " <br><b>Silhouette Score:</b> {sil_score:.3f}\n",
    " </div>\n",
    "\"\"\"\n",
    "kmeans_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "kmeans_map.save(\"2024_KMeans_Crime_Clusters.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gbBb7na5bcn",
    "outputId": "5309c694-b107-4c5f-e231-541acde9077c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped MLP maps: MLP_Crime_Prediction_Maps_2024.zip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === MLP PREDICTION MAPS ===\n",
    "mlp_output_dir = \"mlp_crime_prediction_maps\"\n",
    "os.makedirs(mlp_output_dir, exist_ok=True)\n",
    "mlp_map_files = []\n",
    "\n",
    "mlp_monthly_counts = predict_mlp_pd.groupby([\"Month\", \"Predicted_Crime_Type_MLP\"]).size().unstack(fill_value=0)\n",
    "\n",
    "for month in sorted(predict_mlp_pd[\"Month\"].unique()):\n",
    "    month_df = predict_mlp_pd[predict_mlp_pd[\"Month\"] == month]\n",
    "    crime_map = folium.Map(location=[month_df[\"Lat\"].mean(), month_df[\"Lon\"].mean()], zoom_start=11)\n",
    "\n",
    "    for _, row in month_df.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"Lat\"], row[\"Lon\"]],\n",
    "            radius=3,\n",
    "            color=crime_color_map.get(row[\"Predicted_Crime_Type_MLP\"], 'gray'),\n",
    "            fill=True,\n",
    "            fill_opacity=0.6\n",
    "        ).add_to(crime_map)\n",
    "\n",
    "    crime_counts = mlp_monthly_counts.loc[month]\n",
    "    legend_items = ''.join([\n",
    "        f\"&nbsp;<i style='color:{crime_color_map.get(crime, 'gray')};'>●</i> {crime}: {count}<br>\"\n",
    "        for crime, count in crime_counts.items()\n",
    "    ])\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"position: fixed;\n",
    "    bottom: 50px; left: 50px; width: 180px; height: auto;\n",
    "    border:2px solid grey; z-index:9999; font-size:14px;\n",
    "    background-color:white; padding: 5px;\">\n",
    "    &nbsp;<b>MLP Crime Prediction - {month}</b><br>\n",
    "    {legend_items}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    crime_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "    map_file = f\"{mlp_output_dir}/MLP_Crime_Map_Month_{month}.html\"\n",
    "    crime_map.save(map_file)\n",
    "    mlp_map_files.append(map_file)\n",
    "\n",
    "# Zip MLP map results\n",
    "with zipfile.ZipFile(\"MLP_Crime_Prediction_Maps_2024.zip\", 'w') as zipf:\n",
    "    for file in mlp_map_files:\n",
    "        zipf.write(file, arcname=os.path.basename(file))\n",
    "print(\"Zipped MLP maps: MLP_Crime_Prediction_Maps_2024.zip\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
