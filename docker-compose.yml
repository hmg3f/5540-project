name: crs-app

services:
  # zookeeper
  # zoo1:
  #   image: zookeeper:3.9.3
  #   container_name: zookeeper_1
  #   hostname: zoo1
  #   ports:
  #     - 2181:2181
  #     - 9876:9876
  #   volumes:
  #     - ./zookeeper_config:/conf
  #   environment:
  #     ZOO_MY_ID: 1
  #   networks:
  #     crs_bridge:
  #       ipv4_address: 172.20.0.2

  # hadoop name node
  hnn1:
    image: apache/hadoop:3.4.1
    container_name: namenode
    hostname: namenode
    user: root
    command: [ "/bin/bash", "/start-hdfs.sh" ]
    ports:
      - 9870:9870
    volumes:
      - ./hadoop_namenode:/opt/hadoop/data/namenode
      - ./hadoop_config:/opt/hadoop/etc/hadoop
      - ./start-hdfs.sh:/start-hdfs.sh
    environment:
      HADOOP_HOME: /opt/hadoop
    networks:
      crs_bridge:
        ipv4_address: 172.20.0.3

  # hadoop data node
  hdn1:
    image: apache/hadoop:3.4.1
    depends_on:
      - hnn1
    container_name: datanode_1
    hostname: datanode_1
    user: root
    command: [ "/bin/bash", "/init-datanode.sh" ]
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./hadoop_datanode_1:/opt/hadoop/data/datanode
      - ./hadoop_config:/opt/hadoop/etc/hadoop
      - ./init-datanode.sh:/init-datanode.sh
      - ./data:/data
    networks:
      crs_bridge:
        ipv4_address: 172.20.0.4

  # hadoop resource node
  hrn1:
    image: apache/hadoop:3.4.1
    depends_on:
      - hnn1
    restart: always
    container_name: resourcenode
    hostname: resourcenode
    user: root
    command: [ "/bin/bash", "/init-resourcenode.sh" ]
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./hadoop_config:/opt/hadoop/etc/hadoop
      - ./init-resourcenode.sh:/init-resourcenode.sh
      - ./data:/data
    networks:
      crs_bridge:
        ipv4_address: 172.20.0.30

  # hadoop history server
  hhn1:
    image: apache/hadoop:3.4.1
    depends_on:
      - hnn1
    restart: always
    container_name: historynode
    hostname: historynode
    user: root
    command: [ "/bin/bash", "/init-historynode.sh" ]
    ports:
      - 8188:8188
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./hadoop_timeline:/hadoop/yarn/timeline
      - ./hadoop_config:/opt/hadoop/etc/hadoop
      - ./init-resourcenode.sh:/init-historynode.sh
      - ./data:/data
    networks:
      crs_bridge:
        ipv4_address: 172.20.0.31

  # # kafka controller
  # controller-1:
  #   image: apache/kafka:4.0.0
  #   container_name: controller-1
  #   ports:
  #     - 9093:9093
  #   environment:
  #     KAFKA_NODE_ID: 1
  #     KAFKA_PROCESS_ROLES: controller
  #     KAFKA_LISTENERS: CONTROLLER://:9093
  #     KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
  #     KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  #   networks:
  #     crs_bridge:
  #       ipv4_address: 172.20.0.5

  # # kafka broker
  # broker-1:
  #   image: apache/kafka:4.0.0
  #   container_name: broker-1
  #   ports:
  #     - 9092:9092
  #   volumes:
  #     - ./kafka-init_topics.sh:/opt/kafka/kafka-init_topics.sh
  #   environment:
  #     KAFKA_NODE_ID: 2
  #     KAFKA_PROCESS_ROLES: broker
  #     KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
  #     KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-1:19092,PLAINTEXT_HOST://localhost:9092'
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093
  #     KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  #   depends_on:
  #     - controller-1
  #   post_start:
  #     - command: /opt/kafka/kafka-init_topics.sh
  #   networks:
  #     crs_bridge:
  #       ipv4_address: 172.20.0.6

  spark:
    image: spark:3.5.5-scala2.12-java17-python3-r-ubuntu
    container_name: spark
    hostname: spark
    user: root
    volumes:
      - ./hadoop_config:/opt/hadoop/etc/hadoop
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - SPARK_HOME=/opt/spark
      - SPARK_MASTER=yarn
      - SPARK_SUBMIT_OPTIONS=--master yarn
    networks:
      crs_bridge:
        ipv4_address: 172.20.0.7

networks:
  crs_bridge:
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
